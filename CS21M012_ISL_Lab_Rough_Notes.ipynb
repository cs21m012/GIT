{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38edd92382444b7dbb069f0cb2a53677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efca7452dfba4ea9bab3aadd1e0cb03a",
              "IPY_MODEL_c29192c8a03b42ad88906dee16d1fa64",
              "IPY_MODEL_5149d686cc044b4b9b6b55f13d7ab46d"
            ],
            "layout": "IPY_MODEL_cefed43ea0e549a39eb9811de86b2877"
          }
        },
        "efca7452dfba4ea9bab3aadd1e0cb03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5d56fd4dd9b42af9bc0348cdb9d19fc",
            "placeholder": "​",
            "style": "IPY_MODEL_96c83b7d4d644edfb38c304667b64797",
            "value": "100%"
          }
        },
        "c29192c8a03b42ad88906dee16d1fa64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed0de6471d445e1a1c37b70702dc441",
            "max": 26421880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abfcb8b0e75e40069751d1329781d61a",
            "value": 26421880
          }
        },
        "5149d686cc044b4b9b6b55f13d7ab46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ef44c87cd514d9fa4424c223027a39a",
            "placeholder": "​",
            "style": "IPY_MODEL_ef26583a2c124ea0bea5201fa983559d",
            "value": " 26421880/26421880 [00:01&lt;00:00, 26289906.89it/s]"
          }
        },
        "cefed43ea0e549a39eb9811de86b2877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5d56fd4dd9b42af9bc0348cdb9d19fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c83b7d4d644edfb38c304667b64797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ed0de6471d445e1a1c37b70702dc441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abfcb8b0e75e40069751d1329781d61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ef44c87cd514d9fa4424c223027a39a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef26583a2c124ea0bea5201fa983559d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b4d01e4c7b542759fc8495cf2c86698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9ff7f7d06ae4bd0bfe113196f7e2576",
              "IPY_MODEL_4e20313a321b444d9fc7ad774a13543b",
              "IPY_MODEL_21aa4c701274499889395eb0b9f6cdae"
            ],
            "layout": "IPY_MODEL_4e629fec77824016ab0f15a937f3b0a0"
          }
        },
        "d9ff7f7d06ae4bd0bfe113196f7e2576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_875d3029c8aa4039bf899639f31be676",
            "placeholder": "​",
            "style": "IPY_MODEL_9f513364c4804c798194f8802aff4d35",
            "value": "100%"
          }
        },
        "4e20313a321b444d9fc7ad774a13543b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1551f3ad7807451ca7aa348079df9386",
            "max": 29515,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57b172ee830f4077a521d37778c8905e",
            "value": 29515
          }
        },
        "21aa4c701274499889395eb0b9f6cdae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_372bcfae4b2f486b8163b48641740f65",
            "placeholder": "​",
            "style": "IPY_MODEL_c67db5d8abf94ff7a3f99b41bbb8e3d5",
            "value": " 29515/29515 [00:00&lt;00:00, 214060.60it/s]"
          }
        },
        "4e629fec77824016ab0f15a937f3b0a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "875d3029c8aa4039bf899639f31be676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f513364c4804c798194f8802aff4d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1551f3ad7807451ca7aa348079df9386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b172ee830f4077a521d37778c8905e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "372bcfae4b2f486b8163b48641740f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c67db5d8abf94ff7a3f99b41bbb8e3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e9f112734c14b1cac93b73d67f13548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbc58b32782f43f8b0ef3c34054b200a",
              "IPY_MODEL_e606055984794be1afc6baa4ae2e7681",
              "IPY_MODEL_9c82eeb147e3404a988da9b20e204bae"
            ],
            "layout": "IPY_MODEL_3b70bbac5926484ea86d4457aae0f83e"
          }
        },
        "dbc58b32782f43f8b0ef3c34054b200a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f26c49201e4bcbb096aef753c51dcc",
            "placeholder": "​",
            "style": "IPY_MODEL_45530d666c2a48a4a476ca3e9b1a17ae",
            "value": "100%"
          }
        },
        "e606055984794be1afc6baa4ae2e7681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9401410c5147c6abb756cacc4eb647",
            "max": 4422102,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_354e700161704dc1905d46b37b167886",
            "value": 4422102
          }
        },
        "9c82eeb147e3404a988da9b20e204bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58f3e498ed044b709d6ad3588f0d8d08",
            "placeholder": "​",
            "style": "IPY_MODEL_7c061057f90d42ae84a778ad52810044",
            "value": " 4422102/4422102 [00:00&lt;00:00, 7435227.40it/s]"
          }
        },
        "3b70bbac5926484ea86d4457aae0f83e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f26c49201e4bcbb096aef753c51dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45530d666c2a48a4a476ca3e9b1a17ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e9401410c5147c6abb756cacc4eb647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354e700161704dc1905d46b37b167886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58f3e498ed044b709d6ad3588f0d8d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c061057f90d42ae84a778ad52810044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5aaeb6e962ad48e9b5992b3a2e6f68e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9ec298aa5f84c408da52a47baea94d1",
              "IPY_MODEL_d2001bf8d56e482cb237647285032f57",
              "IPY_MODEL_991ca029be4345b38bcd3cd2145ca600"
            ],
            "layout": "IPY_MODEL_e36dc8011dc14ea3acb0f004058b6275"
          }
        },
        "e9ec298aa5f84c408da52a47baea94d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c541db710c4e528b69cde42d990ba3",
            "placeholder": "​",
            "style": "IPY_MODEL_2a1bec28c8fa424795813a9c30cc0f8e",
            "value": "100%"
          }
        },
        "d2001bf8d56e482cb237647285032f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ecff45446214798bef7b91167c4bb8c",
            "max": 5148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5646d6c50e14ad49fe3de7f955b038a",
            "value": 5148
          }
        },
        "991ca029be4345b38bcd3cd2145ca600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ce2a980b694517b31e5cf674712da1",
            "placeholder": "​",
            "style": "IPY_MODEL_09617249b028497ea1d06a5d650545d6",
            "value": " 5148/5148 [00:00&lt;00:00, 87193.61it/s]"
          }
        },
        "e36dc8011dc14ea3acb0f004058b6275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c541db710c4e528b69cde42d990ba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a1bec28c8fa424795813a9c30cc0f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ecff45446214798bef7b91167c4bb8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5646d6c50e14ad49fe3de7f955b038a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1ce2a980b694517b31e5cf674712da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09617249b028497ea1d06a5d650545d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI - State space search"
      ],
      "metadata": {
        "id": "FzMZL-diAe98"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTPKqaOpBKCN"
      },
      "outputs": [],
      "source": [
        "# Man, Lion, Goat, Cabbage\n",
        "# Left bank to Right bank\n",
        "# Constraint 1 - Lion will eat Goat if man is not there\n",
        "# Constrain 2 - Goat will eat Cabbage if man is not there\n",
        "# discrete state space - categorical features Man (left side or right side), similarly other objects"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wnew = wold - eta * gradL_wold\n",
        "# state of the network or ml model is indicated by 'w'\n",
        "# it is changing due to one action\n",
        "# that action is gradient descent step or weight update step\n",
        "# continuous state space"
      ],
      "metadata": {
        "id": "LJA4l3YDBWj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actions very specific to the problem domain\n",
        "# Man goes alone\n",
        "# Man takes Lion\n",
        "# Man takes Goat\n",
        "# Man takes Cabbage"
      ],
      "metadata": {
        "id": "vCUSx0EsBzUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The first requirement is state space representation \n",
        "# Implicitly or Explicitly"
      ],
      "metadata": {
        "id": "IvJEKKhGB_pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let s[0] - Position of Man\n",
        "# s[1] - .. Lion\n",
        "# s[2] .. Goat\n",
        "# s[3] .. Cabbage\n",
        "# Positions can be 0 or 1; 0 left side and 1 right side\n",
        "def penalty(s):\n",
        "  # constraint 1\n",
        "  if s[0]!=s[1] and s[1]==s[2]:\n",
        "    return 1000.0\n",
        "  # constraint 2\n",
        "  if s[0]!=s[2] and s[2]==s[3]:\n",
        "    return 1000.0\n",
        "  return 0"
      ],
      "metadata": {
        "id": "zV4BUiDPCJeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def go_alone(s1):\n",
        "    s2 = s1.copy()\n",
        "    s2[0] = 1 - s1[0]\n",
        "    return s2\n",
        "\n",
        "def take_lion(s1):\n",
        "  s2 = s1.copy()\n",
        "  if s2[0]==s2[1]:\n",
        "    s2[0] = 1 - s2[0]\n",
        "    s2[1] = 1 - s2[0]\n",
        "  return s2\n",
        "\n",
        "def take_goat(s1):\n",
        "  s2 = s1.copy()\n",
        "  if s2[0]==s2[2]:\n",
        "    s2[0] = 1 - s2[0]\n",
        "    s2[2] = 1 - s2[2]\n",
        "  return s2\n",
        "\n",
        "def take_cabbage(s1):\n",
        "  s2 = s1.copy()\n",
        "  if s2[0]==s2[3]:\n",
        "    s2[0] = 1 - s2[0]\n",
        "    s2[3] = 1 - s2[3]\n",
        "  return s2\n"
      ],
      "metadata": {
        "id": "7tWiGozCCuD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_list = [go_alone, take_lion, take_goat, take_cabbage]"
      ],
      "metadata": {
        "id": "ZDk0QkwKDo0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_state = [0,0,0,0]"
      ],
      "metadata": {
        "id": "I5fk3_IODsdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "goal_state = [1,1,1,1]"
      ],
      "metadata": {
        "id": "ptC2x29JD98R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter = 1000"
      ],
      "metadata": {
        "id": "uDjBTf5lD_qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def state_copy(s):\n",
        "  return s.copy()"
      ],
      "metadata": {
        "id": "UECgMbt8EDIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_state = state_copy(init_state)\n",
        "\n",
        "for i in range(n_iter):\n",
        "  for a in action_list:\n",
        "    if tmp_state==goal_state:\n",
        "      print ('Print the solution..')\n",
        "      break\n",
        "    tmp_state2 = a(tmp_state)\n",
        "    if penalty(tmp_state2) == 0 :\n",
        "      tmp_state = state_copy(tmp_state2)\n",
        "      # Put some DFS type of logic here\n",
        "      # Think of some backtracking logic to explore different states"
      ],
      "metadata": {
        "id": "bNtGF-_kEKL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn"
      ],
      "metadata": {
        "id": "KXdYI05Gmryc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = torch.nn.Softmax(dim=1)\n",
        "m2 = torch.nn.Softmax(dim=2)"
      ],
      "metadata": {
        "id": "T06biuwlmuTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,3) #its hard to interpret for x = torch.rand(2,3,4)"
      ],
      "metadata": {
        "id": "OrncCRFdm4kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWPCcoPJm73n",
        "outputId": "13c86a9c-a54d-464c-9be8-64743baed74c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2809, 0.2739, 0.4466],\n",
            "        [0.3563, 0.0080, 0.3194]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = m1(x)\n",
        "print (y1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0JKCIVEm9G6",
        "outputId": "4c9ca703-9a43-41c7-8330-237be26be6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3151, 0.3129, 0.3719],\n",
            "        [0.3746, 0.2644, 0.3610]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2 = m2(x)\n",
        "print (y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "pjifh7ZNnPBz",
        "outputId": "e4095082-bb46-4be9-a4c1-12b01d7e7f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f5a9304a1b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1834\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbolic differentiation (own)"
      ],
      "metadata": {
        "id": "pDFIqx_8AmgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DerivativeType :\n",
        "  def __init__(self,name=None):\n",
        "    self.name = name\n",
        "  def getname(self):\n",
        "    return self.name\n",
        "  def derivative(self,paramlist=None): # backward function of pytorch\n",
        "    print ('inside derivative',self.name)\n",
        "    return None\n",
        "  def compute(self,paramlist=None): # forward function of pytorch\n",
        "    print ('inside compute',self.name)\n",
        "    return None\n",
        "  def __str__(self):\n",
        "    if self.name is None:\n",
        "      return 'None'\n",
        "    return self.name"
      ],
      "metadata": {
        "id": "NRggPc5cArEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display(derobj_list):\n",
        "  for der in derobj_list:\n",
        "    print (der)"
      ],
      "metadata": {
        "id": "1KFlUa4jGEnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IllegalDerivativeOperation(Exception):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def __str__(self):\n",
        "    return 'IllegalDerivativeOperation'\n",
        "\n",
        "x = IllegalDerivativeOperation()\n",
        "\n",
        "print (x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEI0K14BD6FW",
        "outputId": "5aa61b5f-6d1d-4587-c2ea-d6324594106b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IllegalDerivativeOperation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = DerivativeType('some name xx')\n",
        "x.derivative()\n",
        "x.compute()\n",
        "print (x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klsFkW5nBJrz",
        "outputId": "81b0ecfd-8812-4cbf-9b62-10e53463fa97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside derivative some name xx\n",
            "inside compute some name xx\n",
            "some name xx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConstant(DerivativeType):\n",
        "  def __init__(self,name,value):\n",
        "    super().__init__(name=name)\n",
        "    self.value = value\n",
        "\n",
        "  def derivative(self,paramlist=None):\n",
        "    derout_list = []\n",
        "\n",
        "    if paramlist is not None:\n",
        "      for param in paramlist:\n",
        "        z = MyConstant('zero',0)\n",
        "        derout_list.append(z)\n",
        "    return derout_list\n",
        "\n",
        "  def compute(self):\n",
        "    return self.value\n",
        "\n",
        "  def __str__(self):\n",
        "    return '(' + self.name + ')'\n",
        "    \n",
        "x = MyConstant('y',3)\n",
        "print (x.getname())\n",
        "y = x.derivative([x])\n",
        "print ('printing derivative...')\n",
        "display(y)\n",
        "print (x.compute())\n",
        "\n",
        "print (x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n65mUpxzBwK5",
        "outputId": "f7bd52f0-32a4-4237-8b4a-fa19aed0112c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y\n",
            "printing derivative...\n",
            "(zero)\n",
            "3\n",
            "(y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try :\n",
        "  print ('kali before raise')\n",
        "  raise IllegalDerivativeOperation\n",
        "  print ('kali after raise')\n",
        "except Exception as e:\n",
        "  print (e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J61nCvqUEHaK",
        "outputId": "4b79e1c4-507c-4a5b-e4bc-e17bb3bac428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kali before raise\n",
            "IllegalDerivativeOperation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyVariable(DerivativeType):\n",
        "  def __init__(self,name, value):\n",
        "    super().__init__(name)\n",
        "    self.value = value\n",
        "\n",
        "  def derivative(self,paramlist=None):\n",
        "    if paramlist is None:\n",
        "      raise IllegalDerivativeOperation\n",
        "\n",
        "    der_list = []\n",
        "    if paramlist is not None:\n",
        "      for param in paramlist :\n",
        "        if param.getname() != self.getname():\n",
        "          der_list.append(MyConstant('zero',0))\n",
        "        else :\n",
        "          der_list.append(MyConstant('one',1))\n",
        "    return der_list\n",
        "\n",
        "  def compute(self):\n",
        "    return self.value\n",
        "\n",
        "  def __str__(self):\n",
        "    return '(' + self.name + ')'\n",
        "\n",
        "x = MyVariable('x',1)\n",
        "y = MyVariable('y',2)\n",
        "\n",
        "z = x.derivative([x,y])\n",
        "display(z)\n",
        "\n",
        "print (x.compute())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4znEJzp8DqhR",
        "outputId": "e9bf9405-9b42-4918-ca18-be872643e681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(one)\n",
            "(zero)\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyUMinus(DerivativeType):\n",
        "  def __init__(self,x):\n",
        "    super().__init__()\n",
        "    self.x = x\n",
        "  def derivative(self,paramlist):\n",
        "    derout_list = []\n",
        "    if paramlist is not None:\n",
        "      for param in paramlist:\n",
        "        z = MyUMinus(self.x.derivative([param])[0])\n",
        "        derout_list.append(z)\n",
        "    return derout_list\n",
        "\n",
        "  def compute(self):\n",
        "    return -1 * self.x.compute()\n",
        "\n",
        "  def __str__(self):\n",
        "    return '-' + str(self.x)\n",
        "\n",
        "x = MyVariable('x',1)\n",
        "y = MyVariable('y',23)\n",
        "ux = MyUMinus(x)\n",
        "\n",
        "print (ux)\n",
        "\n",
        "# z = ux.derivative([x,y,x,ux]) ux derivative logic to be fixed\n",
        "z = ux.derivative([x,y]) \n",
        "\n",
        "display(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9mNtE-baBne",
        "outputId": "960afb01-8c88-4397-ec99-24a211876546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-(x)\n",
            "-(one)\n",
            "-(zero)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyAddition(DerivativeType):\n",
        "  def __init__(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "  def derivative(self,paramlist=None):\n",
        "    derout_list = []\n",
        "\n",
        "    if paramlist is not None:\n",
        "      for param in paramlist:\n",
        "        a = self.x.derivative([param])[0]\n",
        "        b = self.y.derivative([param])[0]\n",
        "        c = MyAddition(a,b)\n",
        "        derout_list.append(c)\n",
        "\n",
        "    return derout_list\n",
        "\n",
        "  def compute(self):\n",
        "    z = self.x.compute() + self.y.compute()\n",
        "    return z\n",
        "\n",
        "  def __str__(self):\n",
        "    mystr = '(' + str(self.x) + '+' + str(self.y) + ')'\n",
        "    return mystr\n",
        "\n",
        "\n",
        "x = MyVariable('x',1)\n",
        "y = MyVariable('y',23)\n",
        "\n",
        "print (x,y)\n",
        "\n",
        "z = MyAddition(x,y)\n",
        "\n",
        "print (z)\n",
        "\n",
        "z1 = z.derivative([x,y])\n",
        "\n",
        "display(z1)\n",
        "\n",
        "print (z.compute())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lny4gU-gJ_bV",
        "outputId": "3e24399d-4024-4295-8d99-dbf83633a851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(x) (y)\n",
            "((x)+(y))\n",
            "((one)+(zero))\n",
            "((zero)+(one))\n",
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMultiplication(DerivativeType):\n",
        "  def __init__(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "  def derivative(self,paramlist=None):\n",
        "    derout_list = []\n",
        "    if paramlist is not None:\n",
        "      for param in paramlist:\n",
        "        a = MyMultiplication(self.x.derivative([param])[0], y)\n",
        "        b = MyMultiplication(self.x, self.y.derivative([param])[0])\n",
        "        c = MyAddition(a,b)\n",
        "        derout_list.append(c)\n",
        "    return derout_list\n",
        "\n",
        "  def compute(self):\n",
        "    z = self.x.compute() * self.y.compute()\n",
        "    return z\n",
        "\n",
        "  def __str__(self):\n",
        "    return '('+str(self.x) + '*' + str(self.y)+')'\n",
        "    \n",
        "  \n",
        "x = MyVariable('x',1)\n",
        "y = MyVariable('y',2)\n",
        "\n",
        "z = MyMultiplication(x,y)\n",
        "\n",
        "print (z)\n",
        "\n",
        "t = z.derivative([x,y])\n",
        "\n",
        "display (t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDT1wMlHGCiD",
        "outputId": "5039a60a-b8ab-4855-f982-389b10836538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((x)*(y))\n",
            "(((one)*(y))+((x)*(zero)))\n",
            "(((zero)*(y))+((x)*(one)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = MyVariable('x',1)\n",
        "y = MyVariable('y',1)\n",
        "t1 = MyMultiplication(x,y)\n",
        "t2 = MyAddition(x,t1)\n",
        "t3 = MyMultiplication(t2,t2)\n",
        "print (t3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdqQ_GSBOnuv",
        "outputId": "3becda30-231a-4719-e469-b3b992e7ab9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(((x)+((x)*(y)))*((x)+((x)*(y))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = t3.derivative([x])\n",
        "display(z)\n",
        "print (z[0])\n",
        "print (z[0].compute())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH54eP04VwwG",
        "outputId": "755b09f4-7fc4-4760-e2b7-1b676c10b6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((((one)+(((one)*(y))+((x)*(zero))))*(y))+(((x)+((x)*(y)))*((one)+(((one)*(y))+((x)*(zero))))))\n",
            "((((one)+(((one)*(y))+((x)*(zero))))*(y))+(((x)+((x)*(y)))*((one)+(((one)*(y))+((x)*(zero))))))\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = t3.derivative([x])\n",
        "\n",
        "display (z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf69kVRwQ-bD",
        "outputId": "0c6e15f1-262b-4371-e610-b59c9a4c4155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((((one)+(((one)*(y))+((x)*(zero))))*(y))+(((x)+((x)*(y)))*((one)+(((one)*(y))+((x)*(zero))))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = MyVariable('x',1)\n",
        "y = MyVariable('x',1)\n",
        "t1 = MyAddition(MyMultiplication(x,y),MyConstant('1',1))\n",
        "print (t1)\n",
        "\n",
        "dt = t1.derivative([x])\n",
        "\n",
        "display(dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az10cEI8L6T-",
        "outputId": "29de8d91-0da3-4f4a-dfe4-ec99da803857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(((x)*(x))+(1))\n",
            "((((one)*(x))+((x)*(one)))+(zero))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMulInv(DerivativeType):\n",
        "  def __init__(self,x):\n",
        "    super().__init__()\n",
        "    self.x = x\n",
        "  def derivative(self,paramlist):\n",
        "    deroutlist = []\n",
        "    if paramlist is not None:\n",
        "      for param in paramlist:\n",
        "        ...\n",
        "        ..."
      ],
      "metadata": {
        "id": "MRlZx4d2cGYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLog(DerivativeType):\n",
        "  def __init__(self,x):\n",
        "    super().__init__()\n",
        "    self.x = x\n",
        "\n",
        "  def derivative(self,paramlist):\n",
        "    derout_list = []\n",
        "    if paramlist is not None:\n",
        "      for param in paramlist:\n",
        "        "
      ],
      "metadata": {
        "id": "fNXjZZJtbkX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyExponentiation(DerivativeType):\n",
        "  def __init__(self,x,y):\n",
        "    super().__init__()\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "  def derivative(self,paramlist):\n",
        "    derout_list = []\n",
        "    if paramlist is not None:\n",
        "      for param in paramlist:\n",
        "        a = MyMultiplication(y,MyExponentiation(x,MyAddition(y,MyUMinus(MyConstant('-1')))))\n",
        "        b = MyMultiplication(MyExponentiation(x,y),MyLog(x))\n",
        "\n"
      ],
      "metadata": {
        "id": "Di5gsVk0ZRcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python iterator"
      ],
      "metadata": {
        "id": "HtQzpGOb5734"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VPo9L3In5-GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sympy"
      ],
      "metadata": {
        "id": "ci1VlHAx5_cI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uf7eLlwk6Bfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clarification regarding library function calls"
      ],
      "metadata": {
        "id": "WlCvH1e29lpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the following is an example of a function inside the python library\n",
        "def myfunction(x):\n",
        "  x.__myfunction__()\n",
        "\n",
        "def myfunction2(x):\n",
        "  x.__myfunction2__()\n",
        "\n",
        "# end of example library\n",
        "\n",
        "# your class should implement __xx__() type of function\n",
        "class A :\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def __myfunction__(self):\n",
        "    pass\n",
        "    print ('inside __myfunction__')\n",
        "\n",
        "  def __myfunction2__(self):\n",
        "    print ('inside __myfunction2__')\n",
        "\n",
        "a = A()\n",
        "\n",
        "myfunction(a)\n",
        "myfunction2(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOWVw40m9n6X",
        "outputId": "e52906e8-176e-4d84-f9a3-a9a2e94c9975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside __myfunction__\n",
            "inside __myfunction2__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataLoader:\n",
        "\n",
        "  def __init__(self,batch_size):\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __iter__(self):\n",
        "    self.a = 1\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.a <= self.batch_size:\n",
        "      x = self.a\n",
        "      self.a += 1\n",
        "      print ('returning a row',self.a)\n",
        "      return x\n",
        "    else:\n",
        "      raise StopIteration\n",
        "\n",
        "myclass = MyDataLoader(5)\n",
        "myiter = iter(myclass)\n",
        "\n",
        "for x in myiter:\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XHke941-019",
        "outputId": "9a2af0fb-91d1-43c5-b794-ca67f3f3f5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "returning a row 2\n",
            "1\n",
            "returning a row 3\n",
            "2\n",
            "returning a row 4\n",
            "3\n",
            "returning a row 5\n",
            "4\n",
            "returning a row 6\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 'with' clause"
      ],
      "metadata": {
        "id": "1_ztWwYY_e1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exception class\n",
        "class MyException(Exception):\n",
        "  def __init__(self,msg):\n",
        "    self.msg = msg\n",
        "\n",
        "  def __str__(self):\n",
        "    mystr = 'My Custom Exception ' + self.msg\n",
        "    return mystr"
      ],
      "metadata": {
        "id": "g4pmIBaa_gMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = MyException('abc')\n",
        "t2 = MyException('pqr')\n",
        "print (t1)\n",
        "print (t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4sZgsDT_2Uw",
        "outputId": "51f1331f-342d-41df-af1c-d9e356835fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Custom Exception abc\n",
            "My Custom Exception pqr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try :\n",
        "  print ('Example try')\n",
        "  raise MyException('some msg text text')\n",
        "  print ('After exception is raised (this code will never be reached)')\n",
        "except Exception as eobj:\n",
        "  print ('Exception handling code')\n",
        "  print (eobj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAo212tCAIke",
        "outputId": "5692e5fc-a9bb-4445-8857-79dc89e85f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example try\n",
            "Exception handling code\n",
            "My Custom Exception some msg text text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyClass:\n",
        "  \n",
        "  def __init__(self, name):\n",
        "    print ('initialized',name)\n",
        "    self.name = name\n",
        "\n",
        "  def op1(self, params):\n",
        "    print ('operation 1', params)\n",
        "  \n",
        "  def op2(self, params):\n",
        "    print ('operation 2', params)\n",
        "\n",
        "  def close(self):\n",
        "    print ('inside code',self.name)\n",
        "\n",
        "class MyClassHandler:\n",
        "    def __init__(self1, name):\n",
        "        self1.name = name\n",
        "      \n",
        "    def __enter__(self1):\n",
        "        self1.x = MyClass(self1.name)\n",
        "        return self1.x\n",
        "\n",
        "    # REF - https://stackoverflow.com/questions/22417323/how-do-enter-and-exit-work-in-python-decorator-classes\n",
        "    def __exit__(self1,exc_type, exc_val, tb):\n",
        "      # you can write your own closing logic\n",
        "      return self1\n",
        "  \n"
      ],
      "metadata": {
        "id": "1gG3IE_WAxp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with MyClassHandler('some name') as xobj:\n",
        "    xobj.op1('params 1')\n",
        "    xobj.op2('param 2')\n",
        "    xobj.op1('param 3')\n",
        "    xobj.op1('param xx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtgsH953Bi0X",
        "outputId": "e0f86a0a-32e9-497e-bbfe-6c3f3cb070ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized some name\n",
            "operation 1 params 1\n",
            "operation 2 param 2\n",
            "operation 1 param 3\n",
            "operation 1 param xx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch - Example Neural Network"
      ],
      "metadata": {
        "id": "_A6D68BsbzkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REF - https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
      ],
      "metadata": {
        "id": "U8380YGJcE0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "z8a-KAL-b2f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "38edd92382444b7dbb069f0cb2a53677",
            "efca7452dfba4ea9bab3aadd1e0cb03a",
            "c29192c8a03b42ad88906dee16d1fa64",
            "5149d686cc044b4b9b6b55f13d7ab46d",
            "cefed43ea0e549a39eb9811de86b2877",
            "f5d56fd4dd9b42af9bc0348cdb9d19fc",
            "96c83b7d4d644edfb38c304667b64797",
            "0ed0de6471d445e1a1c37b70702dc441",
            "abfcb8b0e75e40069751d1329781d61a",
            "5ef44c87cd514d9fa4424c223027a39a",
            "ef26583a2c124ea0bea5201fa983559d",
            "3b4d01e4c7b542759fc8495cf2c86698",
            "d9ff7f7d06ae4bd0bfe113196f7e2576",
            "4e20313a321b444d9fc7ad774a13543b",
            "21aa4c701274499889395eb0b9f6cdae",
            "4e629fec77824016ab0f15a937f3b0a0",
            "875d3029c8aa4039bf899639f31be676",
            "9f513364c4804c798194f8802aff4d35",
            "1551f3ad7807451ca7aa348079df9386",
            "57b172ee830f4077a521d37778c8905e",
            "372bcfae4b2f486b8163b48641740f65",
            "c67db5d8abf94ff7a3f99b41bbb8e3d5",
            "7e9f112734c14b1cac93b73d67f13548",
            "dbc58b32782f43f8b0ef3c34054b200a",
            "e606055984794be1afc6baa4ae2e7681",
            "9c82eeb147e3404a988da9b20e204bae",
            "3b70bbac5926484ea86d4457aae0f83e",
            "75f26c49201e4bcbb096aef753c51dcc",
            "45530d666c2a48a4a476ca3e9b1a17ae",
            "9e9401410c5147c6abb756cacc4eb647",
            "354e700161704dc1905d46b37b167886",
            "58f3e498ed044b709d6ad3588f0d8d08",
            "7c061057f90d42ae84a778ad52810044",
            "5aaeb6e962ad48e9b5992b3a2e6f68e7",
            "e9ec298aa5f84c408da52a47baea94d1",
            "d2001bf8d56e482cb237647285032f57",
            "991ca029be4345b38bcd3cd2145ca600",
            "e36dc8011dc14ea3acb0f004058b6275",
            "84c541db710c4e528b69cde42d990ba3",
            "2a1bec28c8fa424795813a9c30cc0f8e",
            "3ecff45446214798bef7b91167c4bb8c",
            "a5646d6c50e14ad49fe3de7f955b038a",
            "a1ce2a980b694517b31e5cf674712da1",
            "09617249b028497ea1d06a5d650545d6"
          ]
        },
        "id": "Dji625w4cD3Y",
        "outputId": "16536025-d61a-4666-91c5-2b85997c6961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/26421880 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38edd92382444b7dbb069f0cb2a53677"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/29515 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b4d01e4c7b542759fc8495cf2c86698"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4422102 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e9f112734c14b1cac93b73d67f13548"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aaeb6e962ad48e9b5992b3a2e6f68e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS3hFxJ9cJ_y",
        "outputId": "c995d045-5b15-402d-fb6d-d9b770135003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYLwtriscOJ2",
        "outputId": "2f1b7bc6-b608-4151-ec13-350f0b6007ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "0Mwie3zxcSah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "FesH2SzicVOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "m9RObiDmcXua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "N16bT9jRX_KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9ocPpc6caeJ",
        "outputId": "ba7f0138-aeb0-42eb-f06e-7268be6e2c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.303668  [    0/60000]\n",
            "loss: 2.295953  [ 6400/60000]\n",
            "loss: 2.272277  [12800/60000]\n",
            "loss: 2.268422  [19200/60000]\n",
            "loss: 2.251653  [25600/60000]\n",
            "loss: 2.209183  [32000/60000]\n",
            "loss: 2.222765  [38400/60000]\n",
            "loss: 2.177465  [44800/60000]\n",
            "loss: 2.173377  [51200/60000]\n",
            "loss: 2.145881  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 46.0%, Avg loss: 2.137391 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.144399  [    0/60000]\n",
            "loss: 2.136784  [ 6400/60000]\n",
            "loss: 2.065311  [12800/60000]\n",
            "loss: 2.091719  [19200/60000]\n",
            "loss: 2.042312  [25600/60000]\n",
            "loss: 1.964676  [32000/60000]\n",
            "loss: 2.009735  [38400/60000]\n",
            "loss: 1.909845  [44800/60000]\n",
            "loss: 1.920094  [51200/60000]\n",
            "loss: 1.860091  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 54.7%, Avg loss: 1.844741 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.876761  [    0/60000]\n",
            "loss: 1.847603  [ 6400/60000]\n",
            "loss: 1.710474  [12800/60000]\n",
            "loss: 1.770515  [19200/60000]\n",
            "loss: 1.674961  [25600/60000]\n",
            "loss: 1.610720  [32000/60000]\n",
            "loss: 1.656593  [38400/60000]\n",
            "loss: 1.540531  [44800/60000]\n",
            "loss: 1.576123  [51200/60000]\n",
            "loss: 1.490498  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.1%, Avg loss: 1.492858 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.554164  [    0/60000]\n",
            "loss: 1.528789  [ 6400/60000]\n",
            "loss: 1.366519  [12800/60000]\n",
            "loss: 1.457582  [19200/60000]\n",
            "loss: 1.349832  [25600/60000]\n",
            "loss: 1.328485  [32000/60000]\n",
            "loss: 1.362602  [38400/60000]\n",
            "loss: 1.274801  [44800/60000]\n",
            "loss: 1.314760  [51200/60000]\n",
            "loss: 1.229986  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.6%, Avg loss: 1.246775 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.313776  [    0/60000]\n",
            "loss: 1.307709  [ 6400/60000]\n",
            "loss: 1.132787  [12800/60000]\n",
            "loss: 1.252620  [19200/60000]\n",
            "loss: 1.129512  [25600/60000]\n",
            "loss: 1.140933  [32000/60000]\n",
            "loss: 1.174711  [38400/60000]\n",
            "loss: 1.103919  [44800/60000]\n",
            "loss: 1.146782  [51200/60000]\n",
            "loss: 1.070253  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.0%, Avg loss: 1.086674 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4otXN-C4ccwK",
        "outputId": "a66f13a9-e503-4b5b-b25f-0341ac02d676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSPqFze-csgZ",
        "outputId": "f4026442-9469-4db2-fff2-05d897f261c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqoeo1X7cvAu",
        "outputId": "7819c308-e459-4305-86eb-226ce67e70a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch - Curve fitting"
      ],
      "metadata": {
        "id": "_Zx73K2Qc1Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REF - https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
      ],
      "metadata": {
        "id": "S7KFbnj6c52g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numpy based approach"
      ],
      "metadata": {
        "id": "byss0qUojoa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Create random input and output data\n",
        "x = np.linspace(0,1,100)\n",
        "y=3+(4*x)+(5*x**2)+(6*x**3)\n",
        "#y = np.sin(x)\n",
        "\n",
        "# Randomly initialize weights\n",
        "a = np.random.randn()\n",
        "b = np.random.randn()\n",
        "c = np.random.randn()\n",
        "d = np.random.randn()\n",
        "\n",
        "learning_rate = 1e-3\n",
        "for t in range(200):\n",
        "    # Forward pass: compute predicted y\n",
        "    # y = a + b x + c x^2 + d x^3\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = np.square(y_pred - y).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # Update weights\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOnSAcfEc_eT",
        "outputId": "d3b08a88-8776-41cb-e005-486df0746a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 5.611758628247737\n",
            "199 3.779481334468664\n",
            "Result: y = 2.6118888602302226 + 5.455542858858748 x + 5.411139477803916 x^2 + 4.100216399808352 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Create random input and output data\n",
        "x = np.linspace(0,1,1000)\n",
        "y = np.sin(x)\n",
        "\n",
        "# Randomly initialize weights\n",
        "a = np.random.randn()\n",
        "b = np.random.randn()\n",
        "c = np.random.randn()\n",
        "\n",
        "learning_rate = 1e-3\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y\n",
        "    # y = a + b x + c x^2 + d x^3\n",
        "    y_pred = a + b * x + c * x ** 2 \n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = np.square(y_pred - y).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    \n",
        "\n",
        "    # Update weights\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    \n",
        "\n",
        "print(f'Result: y = {a} + {b} x + {c} x^2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbLj4nAEC28g",
        "outputId": "e2169e45-7ce3-4e38-c22e-3b92e1bbf116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 8.206591525262678e+51\n",
            "199 6.163987466120722e+103\n",
            "299 4.629783432687346e+155\n",
            "399 3.4774396851712193e+207\n",
            "499 2.6119119694945756e+259\n",
            "599 inf\n",
            "699 inf\n",
            "799 inf\n",
            "899 inf\n",
            "999 inf\n",
            "1099 inf\n",
            "1199 nan\n",
            "1299 nan\n",
            "1399 nan\n",
            "1499 nan\n",
            "1599 nan\n",
            "1699 nan\n",
            "1799 nan\n",
            "1899 nan\n",
            "1999 nan\n",
            "Result: y = nan + nan x + nan x^2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in square\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in multiply\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in multiply\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sK5JNpZYBuAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor based approach (without autograd)"
      ],
      "metadata": {
        "id": "No9_TzeZjsu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.linspace(0,1,100, device=device, dtype=dtype)\n",
        "#y = torch.sin(x)\n",
        "y=3+(4*x)+(5*x*x)+(6*x*x*x)\n",
        "# Randomly initialize weights\n",
        "a = torch.randn((), device=device, dtype=dtype)\n",
        "b = torch.randn((), device=device, dtype=dtype)\n",
        "c = torch.randn((), device=device, dtype=dtype)\n",
        "d = torch.randn((), device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "for t in range(100):\n",
        "    # Forward pass: compute predicted y\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ipeQAyWdSwd",
        "outputId": "e67899a1-b3b5-40bf-d62d-382e3ac89774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 5.723137855529785\n",
            "Result: y = 2.678769826889038 + 5.540377616882324 x + 5.480797290802002 x^2 + 3.6540627479553223 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor based (WITH AUTOGRAD)"
      ],
      "metadata": {
        "id": "iwk4qY29jx5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "#device = torch.device(\"cuda:0\")  # Uncomment this to run on GPU\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "# By default, requires_grad=False, which indicates that we do not need to\n",
        "# compute gradients with respect to these Tensors during the backward pass.\n",
        "x = torch.linspace(0,1,100, device=device, dtype=dtype)\n",
        "#y = torch.sin(x)\n",
        "y=3+(4*x)+(5*x*x)+(6*x*x*x)\n",
        "\n",
        "# Create random Tensors for weights. For a third order polynomial, we need\n",
        "# 4 weights: y = a + b x + c x^2 + d x^3\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "for t in range(100):\n",
        "    # Forward pass: compute predicted y using operations on Tensors.\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss using operations on Tensors.\n",
        "    # Now loss is a Tensor of shape (1,)\n",
        "    # loss.item() gets the scalar value held in the loss.\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Use autograd to compute the backward pass. This call will compute the\n",
        "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
        "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
        "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
        "    loss.backward()\n",
        "\n",
        "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
        "    # because weights have requires_grad=True, but we don't need to track this\n",
        "    # in autograd.\n",
        "    with torch.no_grad():\n",
        "        a -= learning_rate * a.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        c -= learning_rate * c.grad\n",
        "        d -= learning_rate * d.grad\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        a.grad = None\n",
        "        b.grad = None\n",
        "        c.grad = None\n",
        "        d.grad = None\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta39yscrdbW6",
        "outputId": "377e1d75-40f1-4933-c40d-ef73302bb8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 1.0229239463806152\n",
            "Result: y = 3.2255990505218506 + 3.4655909538269043 x + 5.047950267791748 x^2 + 6.187089920043945 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor based WITH AUTOGRAD + OPTIM"
      ],
      "metadata": {
        "id": "LYM9tzAMj5or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\")  # Uncomment this to run on GPU\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "# By default, requires_grad=False, which indicates that we do not need to\n",
        "# compute gradients with respect to these Tensors during the backward pass.\n",
        "x = torch.linspace(0,1,100, dtype=dtype)\n",
        "#y = torch.sin(x)\n",
        "y=3+(4*x)+(5*x*x)+(6*x*x*x)\n",
        "\n",
        "# Create random Tensors for weights. For a third order polynomial, we need\n",
        "# 4 weights: y = a + b x + c x^2 + d x^3\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# 2022 Aug 23 - Kalidas (ykalidas@iittp.ac.in)\n",
        "optimizer = torch.optim.SGD([a,b,c,d], lr=learning_rate, momentum=0)\n",
        "    "
      ],
      "metadata": {
        "id": "Ety2ENm_j4AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(1000):\n",
        "    # Forward pass: compute predicted y using operations on Tensors.\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss using operations on Tensors.\n",
        "    # Now loss is a Tensor of shape (1,)\n",
        "    # loss.item() gets the scalar value held in the loss.\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "\n",
        "    # 2022 Aug 23 - Kalidas (ykalidas@iittp.ac.in)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5IABNnGkbeY",
        "outputId": "fe5e0623-8cdf-4893-a468-eee197588096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 0.8174586296081543\n",
            "199 0.17746180295944214\n",
            "299 0.13403907418251038\n",
            "399 0.10160563886165619\n",
            "499 0.07708349823951721\n",
            "599 0.058543313294649124\n",
            "699 0.04452750086784363\n",
            "799 0.03392999619245529\n",
            "899 0.02591809630393982\n",
            "999 0.019859835505485535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in [a,b,c,d]:\n",
        "  x.requires_grad = False"
      ],
      "metadata": {
        "id": "ofvZo9g9lDln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc_i5tsAkS5x",
        "outputId": "e8f71059-6672-4374-d211-0a9f23a1dc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: y = 2.980103015899658 + 4.01419734954834 x + 5.243313312530518 x^2 + 5.727081298828125 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class LegendrePolynomial3(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input, = ctx.saved_tensors\n",
        "        return grad_output * 1.5 * (5 * input ** 2 - 1)\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\")  # Uncomment this to run on GPU\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "# By default, requires_grad=False, which indicates that we do not need to\n",
        "# compute gradients with respect to these Tensors during the backward pass.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Create random Tensors for weights. For this example, we need\n",
        "# 4 weights: y = a + b * P3(c + d * x), these weights need to be initialized\n",
        "# not too far from the correct result to ensure convergence.\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 5e-6\n",
        "for t in range(2000):\n",
        "    # To apply our Function, we use Function.apply method. We alias this as 'P3'.\n",
        "    P3 = LegendrePolynomial3.apply\n",
        "\n",
        "    # Forward pass: compute predicted y using operations; we compute\n",
        "    # P3 using our custom autograd operation.\n",
        "    y_pred = a + b * P3(c + d * x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Use autograd to compute the backward pass.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    with torch.no_grad():\n",
        "        a -= learning_rate * a.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        c -= learning_rate * c.grad\n",
        "        d -= learning_rate * d.grad\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        a.grad = None\n",
        "        b.grad = None\n",
        "        c.grad = None\n",
        "        d.grad = None\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMHSMx_Kde-T",
        "outputId": "0996aa1d-6c9a-4cc3-a11d-1a17a3eea032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 209.95834350585938\n",
            "199 144.66018676757812\n",
            "299 100.70249938964844\n",
            "399 71.03519439697266\n",
            "499 50.97850799560547\n",
            "599 37.403133392333984\n",
            "699 28.206867218017578\n",
            "799 21.97318458557129\n",
            "899 17.7457275390625\n",
            "999 14.877889633178711\n",
            "1099 12.93176555633545\n",
            "1199 11.610918998718262\n",
            "1299 10.71425724029541\n",
            "1399 10.10548210144043\n",
            "1499 9.692106246948242\n",
            "1599 9.411375045776367\n",
            "1699 9.220745086669922\n",
            "1799 9.091285705566406\n",
            "1899 9.003360748291016\n",
            "1999 8.943639755249023\n",
            "Result: y = -5.394172664097141e-09 + -2.208526849746704 * P3(1.367587154632588e-09 + 0.2554861009120941 x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# For this example, the output y is a linear function of (x, x^2, x^3), so\n",
        "# we can consider it as a linear layer neural network. Let's prepare the\n",
        "# tensor (x, x^2, x^3).\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)\n",
        "\n",
        "# In the above code, x.unsqueeze(-1) has shape (2000, 1), and p has shape\n",
        "# (3,), for this case, broadcasting semantics will apply to obtain a tensor\n",
        "# of shape (2000, 3) \n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. The Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "# The Flatten layer flatens the output of the linear layer to a 1D tensor,\n",
        "# to match the shape of `y`.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "\n",
        "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "    # override the __call__ operator so you can call them like functions. When\n",
        "    # doing so you pass a Tensor of input data to the Module and it produces\n",
        "    # a Tensor of output data.\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n",
        "\n",
        "# You can access the first layer of `model` like accessing the first item of a list\n",
        "linear_layer = model[0]\n",
        "\n",
        "# For linear layer, its parameters are stored as `weight` and `bias`.\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32N6yFtRdm53",
        "outputId": "fa70f0aa-e074-4e4f-f244-b4fe06bf90a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 225.2261199951172\n",
            "199 157.5009765625\n",
            "299 111.08541870117188\n",
            "399 79.2381362915039\n",
            "499 57.36173629760742\n",
            "599 42.317413330078125\n",
            "699 31.960010528564453\n",
            "799 24.821544647216797\n",
            "899 19.896257400512695\n",
            "999 16.49434471130371\n",
            "1099 14.142193794250488\n",
            "1199 12.514185905456543\n",
            "1299 11.386262893676758\n",
            "1399 10.604043960571289\n",
            "1499 10.061051368713379\n",
            "1599 9.683794021606445\n",
            "1699 9.421426773071289\n",
            "1799 9.238815307617188\n",
            "1899 9.11160945892334\n",
            "1999 9.022926330566406\n",
            "Result: y = -0.013745415024459362 + 0.8508179187774658 x + 0.00237131305038929 x^2 + -0.09248790144920349 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Prepare the input tensor (x, x^2, x^3).\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)\n",
        "\n",
        "# Use the nn package to define our model and loss function.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "# Use the optim package to define an Optimizer that will update the weights of\n",
        "# the model for us. Here we will use RMSprop; the optim package contains many other\n",
        "# optimization algorithms. The first argument to the RMSprop constructor tells the\n",
        "# optimizer which Tensors it should update.\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "for t in range(2000):\n",
        "    # Forward pass: compute predicted y by passing x to the model.\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    # Compute and print loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable\n",
        "    # weights of the model). This is because by default, gradients are\n",
        "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "linear_layer = model[0]\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NoBQIwadn27",
        "outputId": "4d5ad53f-c235-47cb-f6f7-2630694420d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 533.353515625\n",
            "199 383.0157775878906\n",
            "299 270.6048583984375\n",
            "399 181.2832489013672\n",
            "499 114.58033752441406\n",
            "599 68.02662658691406\n",
            "699 37.8013916015625\n",
            "799 20.2047119140625\n",
            "899 11.908942222595215\n",
            "999 9.279428482055664\n",
            "1099 8.891770362854004\n",
            "1199 8.95720386505127\n",
            "1299 8.919443130493164\n",
            "1399 8.907357215881348\n",
            "1499 8.928251266479492\n",
            "1599 8.926275253295898\n",
            "1699 8.918866157531738\n",
            "1799 8.918336868286133\n",
            "1899 8.921676635742188\n",
            "1999 8.9215726852417\n",
            "Result: y = -0.0005009158630855381 + 0.8562391996383667 x + -0.0005009331507608294 x^2 + -0.09383225440979004 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class Polynomial3(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate four parameters and assign them as\n",
        "        member parameters.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.a = torch.nn.Parameter(torch.randn(()))\n",
        "        self.b = torch.nn.Parameter(torch.randn(()))\n",
        "        self.c = torch.nn.Parameter(torch.randn(()))\n",
        "        self.d = torch.nn.Parameter(torch.randn(()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        \"\"\"\n",
        "        return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "\n",
        "    def string(self):\n",
        "        \"\"\"\n",
        "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
        "        \"\"\"\n",
        "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3'\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model = Polynomial3()\n",
        "\n",
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters (defined \n",
        "# with torch.nn.Parameter) which are members of the model.\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
        "for t in range(2000):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f'Result: {model.string()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOVbqiqddrz1",
        "outputId": "ab655fca-6708-4bac-834c-ddd07372714f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 2885.638916015625\n",
            "199 1936.072998046875\n",
            "299 1300.877197265625\n",
            "399 875.6904296875\n",
            "499 590.8817138671875\n",
            "599 399.9662780761719\n",
            "699 271.89373779296875\n",
            "799 185.91094970703125\n",
            "899 128.13821411132812\n",
            "999 89.28780364990234\n",
            "1099 63.139102935791016\n",
            "1199 45.523529052734375\n",
            "1299 33.645416259765625\n",
            "1399 25.628427505493164\n",
            "1499 20.212207794189453\n",
            "1599 16.54926109313965\n",
            "1699 14.069504737854004\n",
            "1799 12.388973236083984\n",
            "1899 11.248841285705566\n",
            "1999 10.474541664123535\n",
            "Result: y = 0.029060767963528633 + 0.827519953250885 x + -0.0050134663470089436 x^2 + -0.08917397260665894 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate five parameters and assign them as members.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.a = torch.nn.Parameter(torch.randn(()))\n",
        "        self.b = torch.nn.Parameter(torch.randn(()))\n",
        "        self.c = torch.nn.Parameter(torch.randn(()))\n",
        "        self.d = torch.nn.Parameter(torch.randn(()))\n",
        "        self.e = torch.nn.Parameter(torch.randn(()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        For the forward pass of the model, we randomly choose either 4, 5\n",
        "        and reuse the e parameter to compute the contribution of these orders.\n",
        "\n",
        "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
        "        Python control-flow operators like loops or conditional statements when\n",
        "        defining the forward pass of the model.\n",
        "\n",
        "        Here we also see that it is perfectly safe to reuse the same parameter many\n",
        "        times when defining a computational graph.\n",
        "        \"\"\"\n",
        "        y = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "        for exp in range(4, random.randint(4, 6)):\n",
        "            y = y + self.e * x ** exp\n",
        "        return y\n",
        "\n",
        "    def string(self):\n",
        "        \"\"\"\n",
        "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
        "        \"\"\"\n",
        "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3 + {self.e.item()} x^4 ? + {self.e.item()} x^5 ?'\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model = DynamicNet()\n",
        "\n",
        "# Construct our loss function and an Optimizer. Training this strange model with\n",
        "# vanilla stochastic gradient descent is tough, so we use momentum\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
        "for t in range(30000):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 2000 == 1999:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f'Result: {model.string()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wzLbs4gdwEO",
        "outputId": "88a603e6-9438-4c7b-cc2f-6e70abbd23d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1999 1538.4808349609375\n",
            "3999 696.7999267578125\n",
            "5999 320.11981201171875\n",
            "7999 148.0598907470703\n",
            "9999 72.9036636352539\n",
            "11999 37.97261047363281\n",
            "13999 22.187774658203125\n",
            "15999 14.939539909362793\n",
            "17999 11.581270217895508\n",
            "19999 10.067399978637695\n",
            "21999 9.212265014648438\n",
            "23999 9.114272117614746\n",
            "25999 8.727289199829102\n",
            "27999 8.560704231262207\n",
            "29999 8.880521774291992\n",
            "Result: y = 0.005055580288171768 + 0.8542385697364807 x + -0.001442049746401608 x^2 + -0.09324534982442856 x^3 + 0.00011410781007725745 x^4 ? + 0.00011410781007725745 x^5 ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwBw6ed8dzSA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}